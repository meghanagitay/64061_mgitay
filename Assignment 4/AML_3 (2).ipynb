{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Downloading IMDB Dataset"
      ],
      "metadata": {
        "id": "WR_PhROY9uha"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "HYlZsclewdhZ",
        "outputId": "49241a62-b1e6-490b-f405-878c56dc046c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 80.2M  100 80.2M    0     0  39.0M      0  0:00:02  0:00:02 --:--:-- 39.0M\n"
          ]
        }
      ],
      "source": [
        "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xf aclImdb_v1.tar.gz\n",
        "!rm -r aclImdb/train/unsup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q35skPtfwdha"
      },
      "source": [
        "**Preparing the data**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('aclImdb/val')"
      ],
      "metadata": {
        "id": "oe0mGygPNXyz"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "utLS2B-rwdha"
      },
      "outputs": [],
      "source": [
        "import os, pathlib, shutil, random\n",
        "from tensorflow import keras\n",
        "batch_size = 32\n",
        "base_dir = pathlib.Path(\"aclImdb\")\n",
        "val_dir = base_dir / \"val\"\n",
        "train_n = base_dir / \"train_n\"\n",
        "train_dir = base_dir / \"train\"\n",
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(val_dir / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    random.Random(1337).shuffle(files)\n",
        "    num_val_samples = 10000\n",
        "    val_files = files[-num_val_samples:]\n",
        "    for fname in val_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    val_dir / category / fname)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('aclImdb/train_n')"
      ],
      "metadata": {
        "id": "GnZbMF_0Hp0d"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Sample Size: 100"
      ],
      "metadata": {
        "id": "v8_S7U_tLr3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(train_n / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    num_train_samples=100\n",
        "    train_files = files[-num_train_samples:]\n",
        "    for fname in train_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    train_n / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train_n\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZykVrNW9_mz",
        "outputId": "59067826-42bc-4462-9760-0fc26ca2aedd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 200 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIYRX-EEwdhb"
      },
      "source": [
        "**Preparing integer sequence datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "stZYhV6Gwdhb"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 150\n",
        "max_tokens = 10000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zpv8zlCawdhc"
      },
      "source": [
        "**A sequence model built on one-hot encoded vector sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1Dtqenccwdhc",
        "outputId": "3848f44b-00fc-4d7c-8a27-f96ff2a6dd57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot (TFOpLambda)     (None, None, 10000)       0         \n",
            "                                                                 \n",
            " bidirectional (Bidirection  (None, 64)                2568448   \n",
            " al)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2568513 (9.80 MB)\n",
            "Trainable params: 2568513 (9.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4FhHBichwdhc"
      },
      "source": [
        "**Training a first basic sequence model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wDs1Vmeewdhd",
        "outputId": "180c6a1d-520e-4123-9d31-cfefd8aa7062",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 1s/step - loss: 2.1738 - accuracy: 0.5000 - val_loss: 1.1229 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.9642 - accuracy: 0.5000 - val_loss: 0.7997 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6849 - accuracy: 0.5900 - val_loss: 0.7405 - val_accuracy: 0.5009\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.6825 - accuracy: 0.6900 - val_loss: 0.6886 - val_accuracy: 0.5305\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.5683 - accuracy: 0.7200 - val_loss: 0.6932 - val_accuracy: 0.5419\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.5318 - accuracy: 0.7700 - val_loss: 0.6829 - val_accuracy: 0.5523\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.4688 - accuracy: 0.8600 - val_loss: 0.7164 - val_accuracy: 0.5120\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.3509 - accuracy: 0.8550 - val_loss: 0.6645 - val_accuracy: 0.6003\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.2741 - accuracy: 0.9700 - val_loss: 1.0394 - val_accuracy: 0.5592\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 8s 1s/step - loss: 0.1262 - accuracy: 0.9900 - val_loss: 0.6492 - val_accuracy: 0.6195\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.6497 - accuracy: 0.6199\n",
            "Test acc: 0.620\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awodVR74wdhd"
      },
      "source": [
        "**Instantiating an `Embedding` layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "AuGd7oNbwdhd"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(input_dim=max_tokens, output_dim=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u1MGc8Yhwdhd"
      },
      "source": [
        "**Model that uses an `Embedding` layer trained from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DZnTdOluwdhe",
        "outputId": "f96f145a-51f8-4fbf-80c1-423128e0b146",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_2 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_2 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoogGWNoEe6R",
        "outputId": "c7fb5cdd-af61-4929-9713-570f158c1c99"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 897ms/step - loss: 2.7652 - accuracy: 0.5000 - val_loss: 1.0563 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 5s 778ms/step - loss: 0.8373 - accuracy: 0.5050 - val_loss: 0.8095 - val_accuracy: 0.5121\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 5s 778ms/step - loss: 0.6271 - accuracy: 0.6000 - val_loss: 0.7543 - val_accuracy: 0.5098\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 5s 781ms/step - loss: 0.5455 - accuracy: 0.7250 - val_loss: 0.7173 - val_accuracy: 0.5220\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 5s 778ms/step - loss: 0.4401 - accuracy: 0.8400 - val_loss: 0.6961 - val_accuracy: 0.5424\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 761ms/step - loss: 0.3323 - accuracy: 0.9150 - val_loss: 0.8220 - val_accuracy: 0.5616\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 4s 720ms/step - loss: 0.1128 - accuracy: 0.9850 - val_loss: 0.7040 - val_accuracy: 0.5792\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 5s 740ms/step - loss: 0.0473 - accuracy: 1.0000 - val_loss: 0.9129 - val_accuracy: 0.6132\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 4s 695ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 0.8765 - val_accuracy: 0.5480\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 5s 739ms/step - loss: 0.0199 - accuracy: 1.0000 - val_loss: 0.9521 - val_accuracy: 0.5802\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.6952 - accuracy: 0.5423\n",
            "Test acc: 0.542\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUJLu4MQwdhe"
      },
      "source": [
        "#### Understanding padding and masking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GxDEK0wMwdhe"
      },
      "source": [
        "**Using an `Embedding` layer with masking enabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "J4ufuH21wdhe",
        "outputId": "871da647-f018-4257-a46f-727d7a8ba1e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wgPOFj4Euy9",
        "outputId": "3e8b9ca6-8119-49f5-d6e3-8766b185b0c8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "7/7 [==============================] - 15s 1s/step - loss: 2.3211 - accuracy: 0.5000 - val_loss: 1.1389 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 5s 842ms/step - loss: 0.9436 - accuracy: 0.5000 - val_loss: 0.8777 - val_accuracy: 0.5000\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 5s 849ms/step - loss: 0.6729 - accuracy: 0.5200 - val_loss: 0.7610 - val_accuracy: 0.5000\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 5s 841ms/step - loss: 0.5258 - accuracy: 0.6900 - val_loss: 0.6961 - val_accuracy: 0.5257\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 5s 820ms/step - loss: 0.4187 - accuracy: 0.8550 - val_loss: 0.7101 - val_accuracy: 0.5333\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 800ms/step - loss: 0.2904 - accuracy: 0.9200 - val_loss: 0.7043 - val_accuracy: 0.5480\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 5s 831ms/step - loss: 0.2006 - accuracy: 0.9550 - val_loss: 0.6754 - val_accuracy: 0.5795\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 5s 821ms/step - loss: 0.0939 - accuracy: 0.9900 - val_loss: 0.8295 - val_accuracy: 0.5782\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 5s 801ms/step - loss: 0.0377 - accuracy: 1.0000 - val_loss: 1.2945 - val_accuracy: 0.5914\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 5s 827ms/step - loss: 0.0212 - accuracy: 1.0000 - val_loss: 1.5291 - val_accuracy: 0.6045\n",
            "782/782 [==============================] - 9s 7ms/step - loss: 0.6726 - accuracy: 0.5823\n",
            "Test acc: 0.582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nl8tO2Juwdhe"
      },
      "source": [
        "#### Using pretrained word embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtlOslROwdhe",
        "outputId": "0d1aec91-e925-4951-d920-a7eb8587dba5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-05 03:11:57--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-05-05 03:11:57--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-05-05 03:11:57--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.01MB/s    in 2m 39s  \n",
            "\n",
            "2024-05-05 03:14:36 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip -q glove.6B.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFGWjpSUwdhe"
      },
      "source": [
        "**Parsing the GloVe word-embeddings file**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "O18QPkdywdhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71a242a0-f4b5-4bbe-a11e-7eeb65c887bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400000 word vectors.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "path_to_glove_file = \"glove.6B.100d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(path_to_glove_file) as f:\n",
        "    for line in f:\n",
        "        word, coefs = line.split(maxsplit=1)\n",
        "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print(f\"Found {len(embeddings_index)} word vectors.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ifje0OIGwdhf"
      },
      "source": [
        "**Preparing the GloVe word-embeddings matrix**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "qrHDwTouwdhf"
      },
      "outputs": [],
      "source": [
        "embedding_dim = 100\n",
        "\n",
        "vocabulary = text_vectorization.get_vocabulary()\n",
        "word_index = dict(zip(vocabulary, range(len(vocabulary))))\n",
        "\n",
        "embedding_matrix = np.zeros((max_tokens, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if i < max_tokens:\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKNclXPawdhf"
      },
      "outputs": [],
      "source": [
        "embedding_layer = layers.Embedding(\n",
        "    max_tokens,\n",
        "    embedding_dim,\n",
        "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
        "    trainable=False,\n",
        "    mask_zero=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8Ss9beXwdhf"
      },
      "source": [
        "**Model that uses a pretrained Embedding layer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7_PeVHglwdhf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1b95be7-79d1-4078-d7c9-5e42a2e002b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_4 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "7/7 [==============================] - 9s 904ms/step - loss: 2.5517 - accuracy: 0.5000 - val_loss: 0.9612 - val_accuracy: 0.5000\n",
            "Epoch 2/10\n",
            "7/7 [==============================] - 5s 821ms/step - loss: 0.7901 - accuracy: 0.5300 - val_loss: 0.7686 - val_accuracy: 0.5111\n",
            "Epoch 3/10\n",
            "7/7 [==============================] - 5s 841ms/step - loss: 0.6383 - accuracy: 0.6050 - val_loss: 0.7438 - val_accuracy: 0.5067\n",
            "Epoch 4/10\n",
            "7/7 [==============================] - 5s 820ms/step - loss: 0.6450 - accuracy: 0.6750 - val_loss: 0.7245 - val_accuracy: 0.5141\n",
            "Epoch 5/10\n",
            "7/7 [==============================] - 5s 795ms/step - loss: 0.4167 - accuracy: 0.8700 - val_loss: 0.7237 - val_accuracy: 0.5241\n",
            "Epoch 6/10\n",
            "7/7 [==============================] - 5s 790ms/step - loss: 0.2793 - accuracy: 0.8900 - val_loss: 0.8972 - val_accuracy: 0.5357\n",
            "Epoch 7/10\n",
            "7/7 [==============================] - 5s 805ms/step - loss: 0.1355 - accuracy: 0.9750 - val_loss: 0.7210 - val_accuracy: 0.5812\n",
            "Epoch 8/10\n",
            "7/7 [==============================] - 5s 763ms/step - loss: 0.0559 - accuracy: 0.9900 - val_loss: 0.7509 - val_accuracy: 0.5652\n",
            "Epoch 9/10\n",
            "7/7 [==============================] - 5s 765ms/step - loss: 0.0798 - accuracy: 1.0000 - val_loss: 0.8314 - val_accuracy: 0.5454\n",
            "Epoch 10/10\n",
            "7/7 [==============================] - 5s 750ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 0.9006 - val_accuracy: 0.5838\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.7139 - accuracy: 0.5863\n",
            "Test acc: 0.586\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "seAedOn0OFBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Sample Size: 500"
      ],
      "metadata": {
        "id": "6PDoIdUZOkZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(train_n / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    num_train_samples=500\n",
        "    train_files = files[-num_train_samples:]\n",
        "    for fname in train_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    train_n / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train_n\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b733bfbb-75b9-46aa-cf33-a3cdb34881d8",
        "id": "CsgIxB6JOZ2z"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Z-EsurB9OzFr"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 150\n",
        "max_tokens = 10000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_CDZS-2wj8i"
      },
      "source": [
        "**A sequence model built on one-hot encoded vector sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "outputId": "f05b5a05-e3ce-491b-c96a-73c989402164",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNxXHVmjwj8j"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot_1 (TFOpLambda)   (None, None, 10000)       0         \n",
            "                                                                 \n",
            " bidirectional_5 (Bidirecti  (None, 64)                2568448   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2568513 (9.80 MB)\n",
            "Trainable params: 2568513 (9.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwZa71WBPIaT"
      },
      "source": [
        "**Training a first basic sequence model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "outputId": "f78baa59-9f99-44d0-ee83-4479383d40a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9Ca9R-XPIaT"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 13s 303ms/step - loss: 1.1661 - accuracy: 0.4940 - val_loss: 0.7151 - val_accuracy: 0.5011\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 9s 281ms/step - loss: 0.6633 - accuracy: 0.5960 - val_loss: 0.6619 - val_accuracy: 0.6384\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 9s 282ms/step - loss: 0.5503 - accuracy: 0.7950 - val_loss: 0.6216 - val_accuracy: 0.6769\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 9s 280ms/step - loss: 0.4602 - accuracy: 0.7960 - val_loss: 0.6057 - val_accuracy: 0.6971\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 9s 278ms/step - loss: 0.2135 - accuracy: 0.9630 - val_loss: 0.6627 - val_accuracy: 0.6472\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 9s 277ms/step - loss: 0.1836 - accuracy: 0.9570 - val_loss: 1.8036 - val_accuracy: 0.7305\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 9s 276ms/step - loss: 0.0321 - accuracy: 0.9990 - val_loss: 1.9854 - val_accuracy: 0.7341\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 9s 279ms/step - loss: 0.1126 - accuracy: 0.9920 - val_loss: 2.5462 - val_accuracy: 0.7286\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 9s 277ms/step - loss: 0.2212 - accuracy: 0.9410 - val_loss: 2.5663 - val_accuracy: 0.5011\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 9s 276ms/step - loss: 0.5204 - accuracy: 0.6580 - val_loss: 0.6623 - val_accuracy: 0.6073\n",
            "782/782 [==============================] - 12s 13ms/step - loss: 0.6114 - accuracy: 0.6874\n",
            "Test acc: 0.687\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_Lon4TcPIaU"
      },
      "source": [
        "**Model that uses an `Embedding` layer trained from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "outputId": "89839c8a-387e-4645-e12e-0e31f815c19c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfXei0dAwtAm"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_7 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_4 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd46aea2-9f08-4f10-dc14-4743c270fea9",
        "id": "JFZ3N3gTPIaV"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 11s 252ms/step - loss: 1.0445 - accuracy: 0.5060 - val_loss: 0.6846 - val_accuracy: 0.5515\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 7s 237ms/step - loss: 0.5915 - accuracy: 0.7050 - val_loss: 0.6936 - val_accuracy: 0.5792\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 6s 205ms/step - loss: 0.3520 - accuracy: 0.9030 - val_loss: 1.4653 - val_accuracy: 0.6497\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.1582 - accuracy: 0.9640 - val_loss: 1.0432 - val_accuracy: 0.6002\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 6s 188ms/step - loss: 0.0637 - accuracy: 0.9780 - val_loss: 1.6062 - val_accuracy: 0.6449\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 6s 191ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.6666 - val_accuracy: 0.6391\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 6s 184ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.3257 - val_accuracy: 0.6408\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 6s 175ms/step - loss: 8.0969e-04 - accuracy: 1.0000 - val_loss: 2.5332 - val_accuracy: 0.6406\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 6s 175ms/step - loss: 7.2720e-04 - accuracy: 1.0000 - val_loss: 2.5846 - val_accuracy: 0.6387\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 6s 185ms/step - loss: 0.0015 - accuracy: 0.9990 - val_loss: 2.8915 - val_accuracy: 0.6335\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.6822 - accuracy: 0.5552\n",
            "Test acc: 0.555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z-n_nj7wPIaV"
      },
      "source": [
        "**Using an `Embedding` layer with masking enabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "outputId": "1a111e4a-7096-48d6-ebd3-c2a9e0ac0610",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wnamz0dxCzx"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_8 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_5 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc541b3a-f2b2-4203-d3e3-12dfd75ed21a",
        "id": "Ij465SaPPIaW"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 18s 333ms/step - loss: 1.1140 - accuracy: 0.5110 - val_loss: 0.6888 - val_accuracy: 0.5429\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 7s 229ms/step - loss: 0.5693 - accuracy: 0.7440 - val_loss: 0.6514 - val_accuracy: 0.6176\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 7s 238ms/step - loss: 0.3120 - accuracy: 0.9220 - val_loss: 4.8207 - val_accuracy: 0.6131\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.4042 - accuracy: 0.8530 - val_loss: 0.9986 - val_accuracy: 0.5871\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 6s 202ms/step - loss: 0.2045 - accuracy: 0.9090 - val_loss: 1.4468 - val_accuracy: 0.5681\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 7s 210ms/step - loss: 0.0428 - accuracy: 0.9930 - val_loss: 1.3126 - val_accuracy: 0.5824\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 6s 198ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.4464 - val_accuracy: 0.5846\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0077 - accuracy: 0.9990 - val_loss: 1.5233 - val_accuracy: 0.5835\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 6s 186ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 1.5428 - val_accuracy: 0.5854\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 6s 194ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 1.5801 - val_accuracy: 0.5858\n",
            "782/782 [==============================] - 10s 7ms/step - loss: 0.6534 - accuracy: 0.6166\n",
            "Test acc: 0.617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60c2a15b-69bd-4570-ba25-94b62d8e6fb4",
        "id": "gY_P5Of3PIaW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_9 (InputLayer)        [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_8 (Bidirecti  (None, 64)                73984     \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_8 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "32/32 [==============================] - 11s 266ms/step - loss: 1.0748 - accuracy: 0.5080 - val_loss: 0.6960 - val_accuracy: 0.5224\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 7s 226ms/step - loss: 0.6050 - accuracy: 0.6810 - val_loss: 0.6914 - val_accuracy: 0.5698\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 7s 217ms/step - loss: 0.4774 - accuracy: 0.8120 - val_loss: 0.7889 - val_accuracy: 0.5074\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 7s 215ms/step - loss: 0.3156 - accuracy: 0.8730 - val_loss: 1.0264 - val_accuracy: 0.6497\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 7s 209ms/step - loss: 0.1103 - accuracy: 0.9780 - val_loss: 1.4221 - val_accuracy: 0.6805\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 5s 171ms/step - loss: 0.0518 - accuracy: 0.9940 - val_loss: 1.6037 - val_accuracy: 0.6826\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 6s 181ms/step - loss: 0.0759 - accuracy: 0.9940 - val_loss: 1.4024 - val_accuracy: 0.6441\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 6s 177ms/step - loss: 0.0195 - accuracy: 0.9960 - val_loss: 1.9769 - val_accuracy: 0.6643\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 6s 185ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 1.8606 - val_accuracy: 0.6799\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 5s 163ms/step - loss: 8.7592e-04 - accuracy: 1.0000 - val_loss: 2.1310 - val_accuracy: 0.6894\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.6932 - accuracy: 0.5690\n",
            "Test acc: 0.569\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Sample Size: 1250"
      ],
      "metadata": {
        "id": "uBzzI5ZuRdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('aclImdb/train_n')"
      ],
      "metadata": {
        "id": "6NQ7-oJRRsDq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(train_n / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    num_train_samples=1250\n",
        "    train_files = files[-num_train_samples:]\n",
        "    for fname in train_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    train_n / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train_n\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11865ad9-803e-44d4-d09b-be70c53383e7",
        "id": "78-gznzlRdS0"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2500 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "c1AzSRvpRdS0"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 150\n",
        "max_tokens = 10000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2Y_wRe4y6Bz"
      },
      "source": [
        "**A sequence model built on one-hot encoded vector sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "outputId": "3ad8cfb6-56b2-4f0d-a5c8-aaa453c90162",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lAuWohfy6Bz"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_10 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot_2 (TFOpLambda)   (None, None, 10000)       0         \n",
            "                                                                 \n",
            " bidirectional_9 (Bidirecti  (None, 64)                2568448   \n",
            " onal)                                                           \n",
            "                                                                 \n",
            " dropout_9 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2568513 (9.80 MB)\n",
            "Trainable params: 2568513 (9.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZ5PtGiDRdS0"
      },
      "source": [
        "**Training a first basic sequence model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "outputId": "3641a01f-0fd1-40b1-9170-e3fee59d2077",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRQz_OM6RdS0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 14s 135ms/step - loss: 0.9722 - accuracy: 0.5256 - val_loss: 0.6776 - val_accuracy: 0.5495\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 0.6703 - accuracy: 0.7000 - val_loss: 1.9686 - val_accuracy: 0.7257\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 0.6336 - accuracy: 0.6464 - val_loss: 0.6307 - val_accuracy: 0.6776\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 0.4990 - accuracy: 0.7716 - val_loss: 0.9107 - val_accuracy: 0.5013\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 0.3542 - accuracy: 0.8608 - val_loss: 0.6135 - val_accuracy: 0.7559\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 0.1375 - accuracy: 0.9604 - val_loss: 0.8224 - val_accuracy: 0.7368\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 0.0490 - accuracy: 0.9884 - val_loss: 1.0777 - val_accuracy: 0.7616\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 0.0299 - accuracy: 0.9948 - val_loss: 1.3303 - val_accuracy: 0.7765\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 10s 123ms/step - loss: 0.0146 - accuracy: 0.9964 - val_loss: 1.5270 - val_accuracy: 0.7650\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 10s 124ms/step - loss: 0.0096 - accuracy: 0.9984 - val_loss: 1.4124 - val_accuracy: 0.7598\n",
            "782/782 [==============================] - 12s 13ms/step - loss: 0.6164 - accuracy: 0.7495\n",
            "Test acc: 0.750\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myCvZe0lRdS1"
      },
      "source": [
        "**Model that uses an `Embedding` layer trained from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "outputId": "76dec0b8-c32d-4a29-e4d0-117ec93a04a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cpaz_NMazT5Z"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_6 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_10 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_10 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75dc7f43-9671-4497-84e2-4c6d9f9f80f0",
        "id": "c0O1cgiLRdS1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 15s 152ms/step - loss: 0.8148 - accuracy: 0.5344 - val_loss: 0.6687 - val_accuracy: 0.5749\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 10s 132ms/step - loss: 0.5007 - accuracy: 0.7944 - val_loss: 0.6370 - val_accuracy: 0.6514\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 8s 106ms/step - loss: 0.3206 - accuracy: 0.9032 - val_loss: 1.4512 - val_accuracy: 0.5698\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.2178 - accuracy: 0.9144 - val_loss: 1.3862 - val_accuracy: 0.6866\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 7s 87ms/step - loss: 0.0671 - accuracy: 0.9820 - val_loss: 1.8814 - val_accuracy: 0.6852\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.0360 - accuracy: 0.9900 - val_loss: 2.2309 - val_accuracy: 0.6866\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 6s 77ms/step - loss: 0.0193 - accuracy: 0.9948 - val_loss: 2.4372 - val_accuracy: 0.6967\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.0085 - accuracy: 0.9980 - val_loss: 2.6212 - val_accuracy: 0.6856\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.0056 - accuracy: 0.9988 - val_loss: 2.6310 - val_accuracy: 0.6985\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 6s 73ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7080 - val_accuracy: 0.6946\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.6478 - accuracy: 0.6406\n",
            "Test acc: 0.641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFUvaPCRRdS1"
      },
      "source": [
        "**Using an `Embedding` layer with masking enabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "outputId": "a921c1ae-caa0-43a3-fd33-cd4ddeb27577",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ64912rzcJE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_7 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_11 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_11 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7de0e2e-6805-42e6-ce3b-1ada5d5ac924",
        "id": "3hKjNjG5RdS1"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "79/79 [==============================] - 23s 202ms/step - loss: 0.8879 - accuracy: 0.5508 - val_loss: 0.6447 - val_accuracy: 0.6463\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 10s 126ms/step - loss: 0.4378 - accuracy: 0.8340 - val_loss: 0.8569 - val_accuracy: 0.7694\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 8s 105ms/step - loss: 0.1946 - accuracy: 0.9544 - val_loss: 1.2790 - val_accuracy: 0.7678\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 8s 101ms/step - loss: 0.2898 - accuracy: 0.9048 - val_loss: 1.0174 - val_accuracy: 0.7066\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 7s 94ms/step - loss: 0.0588 - accuracy: 0.9876 - val_loss: 1.6326 - val_accuracy: 0.7351\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 7s 93ms/step - loss: 0.0183 - accuracy: 0.9964 - val_loss: 1.7263 - val_accuracy: 0.7356\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 7s 89ms/step - loss: 0.0178 - accuracy: 0.9984 - val_loss: 1.5227 - val_accuracy: 0.7230\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 7s 85ms/step - loss: 0.0091 - accuracy: 0.9988 - val_loss: 1.6951 - val_accuracy: 0.7275\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 6s 82ms/step - loss: 0.0078 - accuracy: 0.9996 - val_loss: 1.8417 - val_accuracy: 0.7307\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 7s 87ms/step - loss: 0.0076 - accuracy: 0.9996 - val_loss: 1.8756 - val_accuracy: 0.7323\n",
            "782/782 [==============================] - 10s 7ms/step - loss: 0.6457 - accuracy: 0.6388\n",
            "Test acc: 0.639\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e16dab13-a04a-40f6-d0d6-7c8682b2b7d4",
        "id": "De4Pd04CRdS1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_12 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_12 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "79/79 [==============================] - 16s 163ms/step - loss: 0.6865 - accuracy: 0.5452 - val_loss: 0.6176 - val_accuracy: 0.6592\n",
            "Epoch 2/10\n",
            "79/79 [==============================] - 9s 118ms/step - loss: 0.4990 - accuracy: 0.7820 - val_loss: 0.5471 - val_accuracy: 0.7365\n",
            "Epoch 3/10\n",
            "79/79 [==============================] - 9s 113ms/step - loss: 0.2164 - accuracy: 0.9260 - val_loss: 0.5043 - val_accuracy: 0.7887\n",
            "Epoch 4/10\n",
            "79/79 [==============================] - 7s 84ms/step - loss: 0.0901 - accuracy: 0.9712 - val_loss: 0.5653 - val_accuracy: 0.7610\n",
            "Epoch 5/10\n",
            "79/79 [==============================] - 6s 81ms/step - loss: 0.0506 - accuracy: 0.9892 - val_loss: 0.6428 - val_accuracy: 0.7850\n",
            "Epoch 6/10\n",
            "79/79 [==============================] - 7s 90ms/step - loss: 0.0197 - accuracy: 0.9968 - val_loss: 0.7151 - val_accuracy: 0.7835\n",
            "Epoch 7/10\n",
            "79/79 [==============================] - 7s 85ms/step - loss: 0.0164 - accuracy: 0.9980 - val_loss: 0.8157 - val_accuracy: 0.7739\n",
            "Epoch 8/10\n",
            "79/79 [==============================] - 6s 75ms/step - loss: 0.0191 - accuracy: 0.9968 - val_loss: 0.6946 - val_accuracy: 0.7709\n",
            "Epoch 9/10\n",
            "79/79 [==============================] - 6s 79ms/step - loss: 0.0180 - accuracy: 0.9968 - val_loss: 0.8867 - val_accuracy: 0.7736\n",
            "Epoch 10/10\n",
            "79/79 [==============================] - 6s 74ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 1.0289 - val_accuracy: 0.7805\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.5272 - accuracy: 0.7744\n",
            "Test acc: 0.774\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Sample Size: 2500"
      ],
      "metadata": {
        "id": "YXMCio3rVglf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shutil.rmtree('aclImdb/train_n')"
      ],
      "metadata": {
        "id": "V7P3M56SVglg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for category in (\"neg\", \"pos\"):\n",
        "    os.makedirs(train_n / category)\n",
        "    files = os.listdir(train_dir / category)\n",
        "    num_train_samples=2500\n",
        "    train_files = files[-num_train_samples:]\n",
        "    for fname in train_files:\n",
        "        shutil.move(train_dir / category / fname,\n",
        "                    train_n / category / fname)\n",
        "\n",
        "train_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/train_n\", batch_size=batch_size\n",
        ")\n",
        "val_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/val\", batch_size=batch_size\n",
        ")\n",
        "test_ds = keras.utils.text_dataset_from_directory(\n",
        "    \"aclImdb/test\", batch_size=batch_size\n",
        ")\n",
        "text_only_train_ds = train_ds.map(lambda x, y: x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a80ed84-94d9-494c-b7b2-16f13597cc88",
        "id": "Rp2obcJTVglg"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5000 files belonging to 2 classes.\n",
            "Found 20000 files belonging to 2 classes.\n",
            "Found 25000 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "EuAoz-2xVglg"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "max_length = 150\n",
        "max_tokens = 10000\n",
        "text_vectorization = layers.TextVectorization(\n",
        "    max_tokens=max_tokens,\n",
        "    output_mode=\"int\",\n",
        "    output_sequence_length=max_length,\n",
        ")\n",
        "text_vectorization.adapt(text_only_train_ds)\n",
        "\n",
        "int_train_ds = train_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_val_ds = val_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)\n",
        "int_test_ds = test_ds.map(\n",
        "    lambda x, y: (text_vectorization(x), y),\n",
        "    num_parallel_calls=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xJwPBmYGz1bD"
      },
      "source": [
        "**A sequence model built on one-hot encoded vector sequences**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "outputId": "3ada32b4-6512-4d9e-8830-f7ef9627744d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_dpIAk6z1bE"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " tf.one_hot_3 (TFOpLambda)   (None, None, 10000)       0         \n",
            "                                                                 \n",
            " bidirectional_13 (Bidirect  (None, 64)                2568448   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_13 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2568513 (9.80 MB)\n",
            "Trainable params: 2568513 (9.80 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = tf.one_hot(inputs, depth=max_tokens)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbLbXH8ZVglg"
      },
      "source": [
        "**Training a first basic sequence model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "outputId": "e283325b-0e60-4856-8a69-02ebfaa4d9ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bivb8eLSVglg"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 15s 78ms/step - loss: 0.8516 - accuracy: 0.5568 - val_loss: 0.6375 - val_accuracy: 0.7151\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.5591 - accuracy: 0.7310 - val_loss: 1.0986 - val_accuracy: 0.5064\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.3643 - accuracy: 0.8638 - val_loss: 0.8260 - val_accuracy: 0.8029\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.3853 - accuracy: 0.8558 - val_loss: 0.5596 - val_accuracy: 0.7346\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.2971 - accuracy: 0.8838 - val_loss: 0.6625 - val_accuracy: 0.7796\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.1265 - accuracy: 0.9690 - val_loss: 1.1110 - val_accuracy: 0.8191\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0682 - accuracy: 0.9870 - val_loss: 1.3349 - val_accuracy: 0.8164\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0508 - accuracy: 0.9944 - val_loss: 1.4009 - val_accuracy: 0.8163\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 11s 73ms/step - loss: 0.0461 - accuracy: 0.9920 - val_loss: 1.7514 - val_accuracy: 0.7648\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.0612 - accuracy: 0.9852 - val_loss: 1.4720 - val_accuracy: 0.8020\n",
            "782/782 [==============================] - 12s 13ms/step - loss: 0.5897 - accuracy: 0.7146\n",
            "Test acc: 0.715\n"
          ]
        }
      ],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"one_hot_bidir_lstm.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"one_hot_bidir_lstm.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3Kb5Vh1Vglh"
      },
      "source": [
        "**Model that uses an `Embedding` layer trained from scratch**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "outputId": "f4500a63-3c03-4a82-cf4b-72b4a94635fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q87YeDeJ0Fl9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_8 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_14 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_14 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(input_dim=max_tokens, output_dim=256)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881915f7-0caa-4e24-a4ed-dd8d68aa0992",
        "id": "EmlgBmkwVglh"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 22s 118ms/step - loss: 0.8194 - accuracy: 0.5720 - val_loss: 2.3112 - val_accuracy: 0.6988\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 12s 73ms/step - loss: 0.5761 - accuracy: 0.7314 - val_loss: 0.5923 - val_accuracy: 0.7008\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 9s 55ms/step - loss: 0.3440 - accuracy: 0.8676 - val_loss: 0.9168 - val_accuracy: 0.7783\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 8s 51ms/step - loss: 0.2349 - accuracy: 0.9322 - val_loss: 1.4336 - val_accuracy: 0.7509\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 7s 47ms/step - loss: 0.1336 - accuracy: 0.9690 - val_loss: 1.5540 - val_accuracy: 0.7707\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 8s 52ms/step - loss: 0.0771 - accuracy: 0.9898 - val_loss: 1.8127 - val_accuracy: 0.7754\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0604 - accuracy: 0.9906 - val_loss: 1.8832 - val_accuracy: 0.7641\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.0368 - accuracy: 0.9954 - val_loss: 2.1214 - val_accuracy: 0.7624\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 0.0317 - accuracy: 0.9976 - val_loss: 2.1205 - val_accuracy: 0.7685\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 0.0317 - accuracy: 0.9974 - val_loss: 2.1466 - val_accuracy: 0.7667\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.6120 - accuracy: 0.6793\n",
            "Test acc: 0.679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVBxVMBgVglh"
      },
      "source": [
        "**Using an `Embedding` layer with masking enabled**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "outputId": "ff62f32e-5de7-4047-a886-d8a4a516201d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7av0saF0Msv"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding_9 (Embedding)     (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_15 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_15 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = layers.Embedding(\n",
        "    input_dim=max_tokens, output_dim=256, mask_zero=True)(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"relu\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"embeddings_bidir_gru_with_masking.keras\",\n",
        "                                    save_best_only=True)\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"embeddings_bidir_gru_with_masking.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sVpZ8YugVglh",
        "outputId": "32e36a3e-8969-4395-ee39-3b59152e0487"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "157/157 [==============================] - 28s 129ms/step - loss: 0.7560 - accuracy: 0.5732 - val_loss: 0.6146 - val_accuracy: 0.6883\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 13s 83ms/step - loss: 0.4621 - accuracy: 0.8130 - val_loss: 0.6295 - val_accuracy: 0.7498\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 10s 63ms/step - loss: 0.2510 - accuracy: 0.9340 - val_loss: 0.9425 - val_accuracy: 0.7531\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 9s 56ms/step - loss: 0.2841 - accuracy: 0.9124 - val_loss: 1.2972 - val_accuracy: 0.7258\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 8s 54ms/step - loss: 0.1085 - accuracy: 0.9766 - val_loss: 1.5621 - val_accuracy: 0.7710\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 8s 51ms/step - loss: 0.0545 - accuracy: 0.9948 - val_loss: 1.6743 - val_accuracy: 0.7758\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 8s 49ms/step - loss: 0.0452 - accuracy: 0.9964 - val_loss: 1.8152 - val_accuracy: 0.7745\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 8s 48ms/step - loss: 0.0365 - accuracy: 0.9968 - val_loss: 1.9981 - val_accuracy: 0.7786\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 8s 50ms/step - loss: 0.0359 - accuracy: 0.9970 - val_loss: 1.9690 - val_accuracy: 0.7747\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 7s 48ms/step - loss: 0.0316 - accuracy: 0.9972 - val_loss: 1.9940 - val_accuracy: 0.7706\n",
            "782/782 [==============================] - 10s 7ms/step - loss: 0.6169 - accuracy: 0.6790\n",
            "Test acc: 0.679\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XAlRpW04Vglh",
        "outputId": "8a4d1829-5d58-4fb5-a9fb-fa6624bb3442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, None)]            0         \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, None, 256)         2560000   \n",
            "                                                                 \n",
            " bidirectional_16 (Bidirect  (None, 64)                73984     \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2634049 (10.05 MB)\n",
            "Trainable params: 2634049 (10.05 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "157/157 [==============================] - 22s 114ms/step - loss: 0.6495 - accuracy: 0.6144 - val_loss: 0.5654 - val_accuracy: 0.7032\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 11s 72ms/step - loss: 0.3812 - accuracy: 0.8396 - val_loss: 0.4588 - val_accuracy: 0.7876\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 9s 57ms/step - loss: 0.2004 - accuracy: 0.9348 - val_loss: 0.5369 - val_accuracy: 0.7851\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 8s 49ms/step - loss: 0.1011 - accuracy: 0.9692 - val_loss: 0.5764 - val_accuracy: 0.7794\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 8s 49ms/step - loss: 0.0452 - accuracy: 0.9866 - val_loss: 0.7528 - val_accuracy: 0.8041\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 8s 50ms/step - loss: 0.0486 - accuracy: 0.9850 - val_loss: 0.8645 - val_accuracy: 0.7866\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0292 - accuracy: 0.9924 - val_loss: 0.9959 - val_accuracy: 0.7585\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0313 - accuracy: 0.9896 - val_loss: 0.9101 - val_accuracy: 0.7705\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 7s 45ms/step - loss: 0.0176 - accuracy: 0.9952 - val_loss: 0.7951 - val_accuracy: 0.7670\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 7s 42ms/step - loss: 0.0221 - accuracy: 0.9934 - val_loss: 0.9473 - val_accuracy: 0.7918\n",
            "782/782 [==============================] - 7s 7ms/step - loss: 0.4843 - accuracy: 0.7704\n",
            "Test acc: 0.770\n"
          ]
        }
      ],
      "source": [
        "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
        "embedded = embedding_layer(inputs)\n",
        "x = layers.Bidirectional(layers.LSTM(32))(embedded)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\"])\n",
        "model.summary()\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\"glove_embeddings_sequence_model.keras\",\n",
        "                                    save_best_only=True,\n",
        "                                    monitor=\"val_loss\")\n",
        "]\n",
        "model.fit(int_train_ds, validation_data=int_val_ds, epochs=10, callbacks=callbacks)\n",
        "model = keras.models.load_model(\"glove_embeddings_sequence_model.keras\")\n",
        "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
      ]
    }
  ]
}